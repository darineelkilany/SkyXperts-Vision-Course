{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc62c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    " \n",
    "img = cv2.imread('4.2.07.tiff', 0)  \n",
    "plt.imshow(img, cmap='gray'); \n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "plt.show()\n",
    "blur = cv2.GaussianBlur(img, (5,5), 1)\n",
    "log = cv2.Laplacian(blur, cv2.CV_64F)\n",
    "blur1 = cv2.GaussianBlur(img, (5,5), 1)\n",
    "blur2 = cv2.GaussianBlur(img, (5,5), 2)\n",
    "dog = blur1 - blur2\n",
    " \n",
    "filtered = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    " \n",
    "plt.subplot(1,3,2); plt.imshow(log, cmap=\"gray\"); plt.title(\"LoG\")\n",
    "plt.subplot(1,3,3); plt.imshow(dog, cmap=\"gray\"); plt.title(\"DoG\")\n",
    "plt.subplot(1,3,1); plt.imshow(log, cmap=\"gray\"); plt.title(\"bilateral\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e6ba8",
   "metadata": {},
   "source": [
    "loG: softening a photo first, then tracing the outlines with a pencil.\n",
    "DoG: Taking two photos with different levels of blur and subracting them so only the edges stand out\n",
    "Bilateral: like applying a beauty filter that smooths skin but keeps the face shape clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    " \n",
    "img = cv2.imread('4.2.07.tiff',cv2.IMREAD_GRAYSCALE)\n",
    "sift_Detector = cv2.SIFT_create()\n",
    "sift_keypoints, descriptors = sift_Detector.detectAndCompute(img.astype(np.uint8), None)\n",
    "img_sift = cv2.drawKeypoints(img, sift_keypoints,None)\n",
    "cv2.imshow(\"sift keypoints\",img_sift)\n",
    "cv2.waitKey(0)\n",
    "ORB_object = cv2.ORB_create()\n",
    "keypoints = ORB_object.detect(img)\n",
    "keypoints, descriptors = ORB_object.compute(img, keypoints)\n",
    "imageresult = cv2.drawKeypoints(img, keypoints, None, color=(255,0,0), flags=0)\n",
    "cv2.imshow('ORB_image', imageresult)\n",
    "cv2.waitKey(0)\n",
    "orb = cv2.ORB_create()\n",
    "img_keypoints, img_descriptors = orb.detectAndCompute(img,None) \n",
    " \n",
    "cv2.destroyAllWindows()\n",
    "print(\"Number of SIFT keypoints:\", len(sift_keypoints))\n",
    "print(\"Number of ORB keypoints:\", len(keypoints))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fbb207",
   "metadata": {},
   "source": [
    "SIFT number:720\n",
    "ORB number:500\n",
    "SIFT uncovers nearly two and a half times more interest points than ORB’s default setup.  \n",
    "ORB’s preset nfeatures=500 imposes an upper bound on detected points unless you tweak that limit.  \n",
    "SIFT relies on a scale-space Difference-of-Gaussian approach for richer detail extraction, while ORB opts for speed and rotational robustness over sheer point count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59068da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    " \n",
    "img1 = cv2.imread('4.2.07.tiff',cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('4.2.06.tiff',cv2.IMREAD_GRAYSCALE)\n",
    "sift_Detector = cv2.SIFT_create()\n",
    "img1_keypoints, img1_descriptors = sift_Detector.detectAndCompute(img1, None)\n",
    "img2_keypoints, img2_descriptors = sift_Detector.detectAndCompute(img2, None)\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(img1_descriptors, img2_descriptors, k=2)\n",
    "number_of_matches = len(matches)\n",
    "img_matches = cv2.drawMatchesKnn(img1, img1_keypoints, img2, img2_keypoints, matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(img_matches)\n",
    "plt.axis('off')\n",
    "plt.title('SIFT Matches ({number_of_matches} matches)')\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d0473",
   "metadata": {},
   "source": [
    "Most feature matches look correct, but a few mismatches are present. Using FLANN helps improve the matching process by finding closer matches efficiently, and applying a ratio test can further reduce errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0879aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import skimage.util \n",
    "from skimage.util  import random_noise\n",
    "img = cv2.imread('4.2.07.tiff',cv2.IMREAD_GRAYSCALE)\n",
    "# Add 'salt and pepper' noise to the image with density of 0.02\n",
    "noisyImg = random_noise(img, mode=\"s&p\",amount=0.02)\n",
    "noisyImg = np.array(255*noisyImg, dtype=\"uint8\")\n",
    "plt.figure(), plt.imshow(noisyImg, cmap=\"gray\", vmin=0, vmax=255),plt.axis('off'), plt.title('Noisy Image')\n",
    "kernel= np.array([[-1,5,-1],[0,-1,0]])\n",
    "sharpened= cv2.filter2D(img,-1,kernel)\n",
    "\n",
    "blur1 = cv2.GaussianBlur(img, (5,5), 1)\n",
    "blur2 = cv2.GaussianBlur(img, (5,5), 2)\n",
    "dog = blur1 - blur2\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,3,3); plt.imshow(dog, cmap=\"gray\"); plt.title(\"DoG\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dfd289",
   "metadata": {},
   "source": [
    "When I added noise, the edges became messy and harder to match. Sharpening, on the other hand, made the features stand out more, so matching was easier. Noise hurts detection, sharpening helps it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
